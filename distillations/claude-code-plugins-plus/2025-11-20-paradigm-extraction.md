# Paradigm Extraction: Claude Code Plugins Plus

**Investigation ID:** `claude-code-plugins-plus-paradigm-extraction-2025-11-20`
**Date:** 2025-11-20
**Level:** 4 (Wisdom/Abstraction - Worldview Shifts)
**Methodology:** Paradigm Extraction & Mental Model Analysis
**Target:** https://github.com/jeremylongshore/claude-code-plugins-plus
**Dependencies:** Complete Wisdom Ladder (Levels 1-4)

---

## Executive Summary

Analysis reveals **7 fundamental paradigm shifts** demonstrated by this repository, representing transitions from traditional software development worldviews to AI-native mental models. These aren't incremental improvementsâ€”they're **conceptual inversions** that require rethinking core assumptions about documentation, APIs, quality, and system design. The meta-paradigm: **From Human-Centric Computing â†’ AI-Native Computing**, where systems are designed for AI operation first, human interaction second.

**Critical Insight:** These paradigms are interconnectedâ€”adopting one often requires adopting several. They form a coherent worldview shift, not isolated changes.

---

## Paradigm 1: **From Documentation-as-Afterthought â†’ Documentation-as-Executable**

### Old Paradigm (Traditional Software)

**Mental Model:**
```
1. Write code (executable)
2. (Optional) Write docs (explanation)
3. Docs lag behind code (outdated)
4. "Code is truth, docs are helpful"
```

**Assumptions:**
- Code is the primary artifact
- Documentation supplements understanding
- Docs for humans, code for machines
- Outdated docs are tolerable

**Worldview:** **Code-First Development**

---

### New Paradigm (AI-Native)

**Mental Model:**
```
1. Write documentation (SKILL.md = specification)
2. AI interprets docs as instructions
3. Docs ARE the executable artifact
4. "Docs are truth, code supports docs"
```

**Assumptions:**
- Documentation is executable specification
- Docs for AI, UI for humans
- Outdated docs break functionality
- Documentation precision matters more than brevity

**Worldview:** **Documentation-First Development**

---

### The Shift

| Dimension | Old | New |
|-----------|-----|-----|
| **Primary Artifact** | Code | Documentation |
| **Doc Consumer** | Human developers | AI agents |
| **Doc Quality Bar** | "Helpful if accurate" | "Must be precise and complete" |
| **Maintenance** | Update when convenient | Update breaks behavior |
| **Tool** | Optional (JavaDoc, etc.) | Mandatory (YAML frontmatter) |

**Evidence from Investigation:**
- SKILL.md files are **execution specifications** (not references)
- Trigger phrases = invocation logic (not examples)
- Tool permissions = architectural declarations (not suggestions)
- Version tracking = semantic versioning of "docs as code"

**Quote:**
> "In AI-native systems, you write documentation firstâ€”it IS the program."

---

### Implications for Adoption

**What Changes:**
- âœ… Documentation becomes CI/CD artifact (validated, versioned)
- âœ… Docs written by developers (not technical writers)
- âœ… Schema enforcement (YAML, JSON schema validation)
- âœ… Doc generation tools (Vertex AI, templates)

**What Becomes Obsolete:**
- âŒ "We'll document later" mindset
- âŒ Docs as separate phase (sprint 1: code, sprint 2: docs)
- âŒ Tolerance for outdated docs

**Resistance Points:**
- ðŸ’­ "Documentation takes too long" (true, but necessary)
- ðŸ’­ "Code should be self-documenting" (for humans, but AI needs explicit specifications)
- ðŸ’­ "Docs always get out of sync" (in old model yes, in new model docs = execution)

---

## Paradigm 2: **From Programmatic APIs â†’ Linguistic APIs**

### Old Paradigm (Function Calls)

**Mental Model:**
```
User â†’ Function Signature â†’ Type Checking â†’ Execution
Example: security.scan(target="code", depth=2)
```

**Assumptions:**
- Exact syntax required (function names, parameters)
- Type systems enforce correctness
- Documentation explains API (but invocation is programmatic)
- Single correct invocation path

**Worldview:** **Syntax-Driven Interaction**

---

### New Paradigm (Natural Language Invocation)

**Mental Model:**
```
User â†’ Intent Expression â†’ Semantic Matching â†’ Skill Activation
Example: "scan this code for security vulnerabilities"
```

**Assumptions:**
- Multiple invocation patterns accepted ("scan code", "check security", "find vulnerabilities")
- Semantic similarity determines matching (not exact syntax)
- Trigger phrases document activation logic
- Context-aware disambiguation

**Worldview:** **Intent-Driven Interaction**

---

### The Shift

| Dimension | Old | New |
|-----------|-----|-----|
| **Interface** | Function signatures | Trigger phrases |
| **Invocation** | Exact syntax | Semantic matching |
| **Type System** | Static types | Tool permissions (capabilities) |
| **Learning Curve** | Memorize API | Express intent naturally |
| **Error Handling** | Compile/runtime errors | Activation failure (silent) |

**Evidence from Investigation:**
- Skills activate through **conversational context** (not `/command` syntax)
- Trigger phrases: "monitor CPU", "analyze performance", "optimize code"
- Soft matching: Variations accepted ("check CPU load" â‰ˆ "monitor CPU usage")
- Silent activation: No explicit invocation required

**Quote:**
> "Make intent the interface, not syntax."

---

### Implications for Adoption

**What Changes:**
- âœ… API design = linguistic design (choose activation phrases carefully)
- âœ… Testing includes conversational scenarios
- âœ… Documentation explicitly lists trigger phrases
- âœ… User training focuses on intent expression (not function memorization)

**What Becomes Obsolete:**
- âŒ Comprehensive API reference docs (function by function)
- âŒ Exact syntax requirements
- âŒ Parameter validation (AI interprets intent)

**Resistance Points:**
- ðŸ’­ "Natural language is ambiguous" (true, but semantic matching handles variations)
- ðŸ’­ "How do I know what's available?" (trigger phrase documentation)
- ðŸ’­ "What if I phrase it wrong?" (multiple patterns accepted)

---

## Paradigm 3: **From Permissions-as-Enforcement â†’ Permissions-as-Documentation**

### Old Paradigm (Runtime Enforcement)

**Mental Model:**
```
User â†’ Request Action â†’ Permission Check â†’ Allow/Deny
Example: if (hasPermission("write")) { execute(); } else { deny(); }
```

**Assumptions:**
- Permissions are runtime gates
- System enforces boundaries
- Violations blocked by security layer
- Trust through prevention

**Worldview:** **Enforcement-Based Security**

---

### New Paradigm (Declarative Constraints)

**Mental Model:**
```
Developer â†’ Declare Permissions â†’ AI Reads Context â†’ Behaves Accordingly
Example: allowed-tools: Read, Grep, Bash â†’ Claude knows to analyze, not modify
```

**Assumptions:**
- Permissions are architectural declarations
- AI interprets as guidance (not hard constraint)
- Violations prevented through context (not enforcement)
- Trust through transparency

**Worldview:** **Declaration-Based Trust**

---

### The Shift

| Dimension | Old | New |
|-----------|-----|-----|
| **Purpose** | Enforcement (prevent violations) | Documentation (communicate intent) |
| **Mechanism** | Runtime checks | Context shaping |
| **Trust Model** | Distrust (prevent abuse) | Trust (guide behavior) |
| **Failure Mode** | Access denied error | Behavior deviation |
| **Auditability** | Logs violations | Documents intent |

**Evidence from Investigation:**
- `allowed-tools` field = declaration (not enforcement layer)
- Principle of least privilege applied (minimal tool sets)
- Tool categories = semantic groupings (read-only, code editing, etc.)
- Claude reads permissions as context (shapes behavior)

**Quote:**
> "Permissions aren't gatesâ€”they're specifications."

---

### Implications for Adoption

**What Changes:**
- âœ… Security through architecture (not runtime enforcement)
- âœ… Permission declarations visible to all (transparency)
- âœ… Categories replace granular permissions (semantic grouping)
- âœ… Trust model shifts (guide AI behavior vs. prevent abuse)

**What Becomes Obsolete:**
- âŒ Fine-grained permission matrices
- âŒ Runtime access control lists
- âŒ Security through obscurity

**Resistance Points:**
- ðŸ’­ "What if AI ignores permissions?" (context shapes behavior, but not absolute)
- ðŸ’­ "This isn't 'real' security" (correctâ€”it's trust-based, requires AI alignment)
- ðŸ’­ "Can't audit violations" (true, but can audit declarations)

---

## Paradigm 4: **From Explicit Invocation â†’ Ambient Activation**

### Old Paradigm (Command-Driven)

**Mental Model:**
```
User â†’ /command â†’ Explicit Execution â†’ Notification â†’ Result
Example: /test â†’ "Running tests..." â†’ "Tests complete (5 passed)"
```

**Assumptions:**
- Users explicitly invoke capabilities
- System notifies of actions
- Awareness of tool usage (logs, messages)
- User controls timing

**Worldview:** **Explicit Control**

---

### New Paradigm (Context-Aware Activation)

**Mental Model:**
```
User â†’ Express Intent â†’ Silent Activation â†’ Seamless Behavior â†’ Detect Through Quality
Example: "I need tests" â†’ (skill activates silently) â†’ Claude generates tests â†’ User sees high-quality result
```

**Assumptions:**
- System infers capability needs from context
- No notification of activation (silent)
- Detection through outcome quality
- AI controls timing (when appropriate)

**Worldview:** **Ambient Intelligence**

---

### The Shift

| Dimension | Old | New |
|-----------|-----|-----|
| **Invocation** | Explicit command | Contextual inference |
| **Feedback** | Notification ("Skill X active") | Silent (detect through behavior) |
| **User Awareness** | High (saw invocation) | Low (inferred from outcome) |
| **UX Philosophy** | Transparency | Seamlessness |
| **Control** | User-driven | Context-driven |

**Evidence from Investigation:**
- Skills activate **without notification** (by design)
- User guide teaches detection: "How to know if skill activated"
- Activation through semantic resonance (conversation triggers)
- UX philosophy: Interruption-free assistance

**Quote:**
> "The best assistance is invisible until needed."

---

### Implications for Adoption

**What Changes:**
- âœ… Trigger phrase design becomes critical UX concern
- âœ… User training shifts (expression over invocation)
- âœ… Quality of outcomes = trust signal
- âœ… "How do I know it worked?" documentation required

**What Becomes Obsolete:**
- âŒ Command menus (explicit lists of capabilities)
- âŒ Status indicators ("Skill X is active")
- âŒ Explicit on/off toggles

**Resistance Points:**
- ðŸ’­ "I want to know what's happening" (valid, but interruptions harm flow)
- ðŸ’­ "How do I control which skills activate?" (through context and phrasing)
- ðŸ’­ "What if wrong skill activates?" (detection through behavior, rephrase if needed)

---

## Paradigm 5: **From Feature Innovation â†’ Standards Innovation**

### Old Paradigm (Novel Capabilities)

**Mental Model:**
```
Competitive Advantage = Unique Features
Market Position = "We have X that competitors don't"
Development Focus = Build novel functionality
```

**Assumptions:**
- Innovation means new features
- Differentiation through capabilities
- More features = better product
- Custom solutions beat standard solutions

**Worldview:** **Feature-Driven Competition**

---

### New Paradigm (Conformance Excellence)

**Mental Model:**
```
Competitive Advantage = Perfect Standards Compliance
Market Position = "We're 100% compliant (industry-first)"
Development Focus = Implement external standards fully
```

**Assumptions:**
- Innovation means perfect execution of standards
- Differentiation through quality signals
- Compliance = trust = adoption
- Standard solutions beat custom solutions (in platform ecosystems)

**Worldview:** **Standards-Driven Competition**

---

### The Shift

| Dimension | Old | New |
|-----------|-----|-----|
| **Innovation** | Novel features | Perfect conformance |
| **Differentiation** | Unique capabilities | Quality signals |
| **Development Priority** | Build new | Implement standards |
| **Marketing** | Feature lists | Compliance claims |
| **Competitive Moat** | Proprietary tech | Reference implementation status |

**Evidence from Investigation:**
- **3-day migration** to achieve 100% 2025 schema compliance
- **Marketing:** "Industry-first", "Only marketplace 100% compliant"
- **Competitor analysis:** Others 0-10% compliant
- **Strategic choice:** Pause features for standards

**Quote:**
> "When everyone has features, conformance becomes the feature."

---

### Implications for Adoption

**What Changes:**
- âœ… Standards tracking (monitor external specifications)
- âœ… Compliance audits (measure conformance gaps)
- âœ… Marketing shifts (claim quality through standards)
- âœ… Development cycles include "conformance sprints"

**What Becomes Obsolete:**
- âŒ "Innovate or die" (conformance can differentiate)
- âŒ Custom standards (follow external, don't invent)
- âŒ Feature-count competition

**Resistance Points:**
- ðŸ’­ "Standards are boring" (yes, but strategic)
- ðŸ’­ "We should innovate beyond standards" (platform lock-in risk)
- ðŸ’­ "Conformance doesn't differentiate" (falseâ€”when others don't conform, it does)

---

## Paradigm 6: **From Manual Quality â†’ Automated Quality Infrastructure**

### Old Paradigm (Human Enforcement)

**Mental Model:**
```
Quality = Code Review + Testing + Standards Docs
Enforcement = Humans check compliance
Scale Limit = Team capacity (doesn't scale)
```

**Assumptions:**
- Humans maintain quality standards
- Code review catches issues
- Documentation states expectations
- Quality requires judgment (can't automate)

**Worldview:** **Human-Gated Quality**

---

### New Paradigm (Infrastructure-Enforced Quality)

**Mental Model:**
```
Quality = Validators + CI Gates + Auto-Fix Tools
Enforcement = Automated tooling
Scale Limit = None (tooling scales infinitely)
```

**Assumptions:**
- Tooling enforces quality standards
- Humans design tooling (not gate every change)
- Automated checks are reliable
- Quality can be codified (if standard is clear)

**Worldview:** **Infrastructure-Gated Quality**

---

### The Shift

| Dimension | Old | New |
|-----------|-----|-----|
| **Enforcement** | Manual review | Automated validation |
| **Gatekeeper** | Senior developers | CI/CD pipeline |
| **Scale** | Limited by human capacity | Unlimited (tooling scales) |
| **Consistency** | Variable (humans differ) | Consistent (tooling doesn't) |
| **Cost** | High (senior time expensive) | Low (compute cheap) |

**Evidence from Investigation:**
- **claude-plugin-validator package:** 538 lines of validation + auto-fix
- **Python validation scripts:** Schema enforcement
- **GitHub Actions CI:** Quality gates in pipeline
- **Bulk fixes:** 120 LICENSEs added automatically

**Quote:**
> "Automate quality gates or they won't be enforced."

---

### Implications for Adoption

**What Changes:**
- âœ… Invest in tooling (validators, linters, formatters)
- âœ… CI/CD becomes quality enforcer (not just deployment)
- âœ… Auto-fix where possible (remediate automatically)
- âœ… Metrics tracking (% compliant, coverage, etc.)

**What Becomes Obsolete:**
- âŒ "Just follow the style guide" (humans forget)
- âŒ Manual quality reviews (doesn't scale)
- âŒ "We'll review it before release" (review every commit via CI)

**Resistance Points:**
- ðŸ’­ "Tooling can't catch everything" (true, but catches most)
- ðŸ’­ "Code review provides context" (yes, but focus on design not style)
- ðŸ’­ "Building tooling takes time" (upfront cost, long-term savings)

---

## Paradigm 7: **From Human-Centric Systems â†’ AI-Native Systems**

### Old Paradigm (Humans Operate, AI Assists)

**Mental Model:**
```
Human â†’ Uses Tool â†’ AI Provides Suggestions â†’ Human Decides â†’ Human Acts
Example: Developer writes code â†’ Copilot suggests â†’ Developer accepts/rejects
```

**Assumptions:**
- Humans are primary operators
- AI is assistant/copilot
- Interfaces designed for human interaction
- Humans in the loop for all decisions

**Worldview:** **AI-Assisted Development** (Copilot Model)

---

### New Paradigm (AI Operates, Humans Provide Context)

**Mental Model:**
```
Human â†’ Provides Intent/Constraints â†’ AI Reads Docs â†’ AI Acts â†’ Human Validates Outcome
Example: Human writes plugin README â†’ AI generates SKILL.md â†’ Claude uses plugin â†’ Human checks results
```

**Assumptions:**
- AI is primary operator
- Humans provide direction/validation
- Interfaces designed for AI consumption (YAML, explicit structures)
- Humans on the loop (not in the loop)

**Worldview:** **AI-Native Development** (System Owner Model)

---

### The Shift

| Dimension | Old | New |
|-----------|-----|-----|
| **Primary User** | Human developer | AI agent |
| **Interface** | GUI, CLI, IDE | Documentation, YAML, schemas |
| **Workflow** | Human operates, AI assists | AI operates, human directs |
| **Optimization For** | Human readability | Machine parseability |
| **Control Model** | Humans in the loop (every step) | Humans on the loop (validation) |

**Evidence from Investigation:**
- **Recursive AI development:** AI generates SKILL.md â†’ Claude reads â†’ extends capabilities
- **Documentation-first:** Optimized for AI parsing (YAML frontmatter) not human reading
- **Silent activation:** AI decides when to engage capabilities
- **Validation layers:** Humans validate outcomes (not every action)

**Quote:**
> "In AI-native systems, optimize for machine clarity first, human comprehension second."

---

### Implications for Adoption

**What Changes:**
- âœ… Design systems for AI consumption (structured formats)
- âœ… Documentation becomes primary interface
- âœ… Humans shift to validation/direction (not operation)
- âœ… "How does AI use this?" = primary design question

**What Becomes Obsolete:**
- âŒ "Make it easy for humans" as sole design criterion
- âŒ Purely visual interfaces (if AI can't parse)
- âŒ "Humans must approve every action" (too slow)

**Resistance Points:**
- ðŸ’­ "I want control" (valid, but slows AI potential)
- ðŸ’­ "What if AI makes mistakes?" (validation model, not prevention)
- ðŸ’­ "Feels like losing agency" (paradigm shift, not lossâ€”delegation)

---

## Meta-Paradigm: **The Inversion**

All 7 paradigms share a common threadâ€”an **inversion of primary/secondary**:

| Traditional | AI-Native |
|-------------|-----------|
| Code primary, docs secondary | Docs primary, code secondary |
| Syntax required, intent inferred | Intent required, syntax inferred |
| Enforcement prevents, trust suspects | Declaration guides, trust assumes |
| Explicit control, ambient assists | Ambient operates, explicit validates |
| Features differentiate, standards baseline | Standards differentiate, features baseline |
| Humans enforce, tools assist | Tools enforce, humans design |
| Humans operate, AI assists | AI operates, humans direct |

**The Pattern:** **Flip the hierarchy** when AI becomes the primary consumer/operator.

---

## Paradigm Adoption Challenges

### Challenge 1: Cognitive Dissonance

**Symptom:** "This feels backwards"
**Cause:** Paradigms conflict with ingrained mental models
**Resolution:** Recognize inversion is intentional (not mistake)

**Example:** "Why write docs first? I think better in code!"
**Answer:** Because AI reads docs as instructions (not references)

---

### Challenge 2: Loss of Control Perception

**Symptom:** "I don't know what's happening"
**Cause:** Silent activation, context-driven behavior
**Resolution:** Detection through outcomes (not notifications)

**Example:** "How do I know a skill activated?"
**Answer:** Claude exhibits domain expertise, uses specialized language

---

### Challenge 3: Trust Model Shift

**Symptom:** "What if AI ignores permissions?"
**Cause:** No runtime enforcement (declaration-based)
**Resolution:** Trust through alignment (not prevention)

**Example:** "Permissions don't stop AI from writing files"
**Answer:** Correctâ€”permissions guide behavior, not enforce boundaries

---

### Challenge 4: Quality Without Humans

**Symptom:** "Machines can't judge quality"
**Cause:** Belief that quality requires human judgment
**Resolution:** Codify standards, automate checks

**Example:** "Code review is essential"
**Answer:** For design, yes. For style/syntax, tools better.

---

## Interconnected Paradigms

These 7 paradigms aren't independentâ€”they form a **coherent worldview**:

```
Documentation-as-Executable
    â†“ enables
Linguistic APIs (docs describe invocation)
    â†“ uses
Permissions-as-Documentation (tool declarations)
    â†“ enables
Ambient Activation (context-driven)
    â†“ requires
Standards Innovation (external specs guide design)
    â†“ enforced by
Automated Quality (tooling validates)
    â†“ culminates in
AI-Native Systems (AI operates, humans direct)
```

**Implication:** Adopting one paradigm often **requires** adopting others. Can't have linguistic APIs without documentation-as-executable. Can't have ambient activation without declaration-based trust.

---

## Adoption Roadmap

### Phase 1: Foundation (Months 1-3)

**Goal:** Establish documentation-first culture

**Actions:**
1. Write documentation before code (reversal of habit)
2. Use YAML frontmatter (structured, parseable)
3. Validate docs in CI (catch errors early)
4. Version docs semantically (treat as code)

**Success Metric:** 80%+ of features have docs-first

---

### Phase 2: Linguistic Interfaces (Months 3-6)

**Goal:** Design natural language APIs

**Actions:**
1. Document trigger phrases (explicit activation patterns)
2. Test conversational scenarios (not just function calls)
3. Accept multiple invocation patterns (soft matching)
4. Teach users intent expression (not syntax memorization)

**Success Metric:** 50%+ capabilities accessible via natural language

---

### Phase 3: Quality Infrastructure (Months 6-9)

**Goal:** Automate quality enforcement

**Actions:**
1. Build validators (schema checks, linters)
2. Add CI gates (fail builds on violations)
3. Implement auto-fix (remediate programmatically)
4. Track metrics (% compliant, coverage)

**Success Metric:** 90%+ quality checks automated

---

### Phase 4: AI-Native Design (Months 9-12)

**Goal:** Optimize for AI operation

**Actions:**
1. Design for AI consumption first (structured formats)
2. Enable ambient activation (context-driven behavior)
3. Shift humans to validation (not operation)
4. Implement recursive AI (AI generates for AI)

**Success Metric:** AI handles 70%+ routine operations autonomously

---

## Comparison to Prior Investigations

### vs. Kindroid (Linguistic Software)

**Shared:** Documentation-as-executable, linguistic interfaces
**Different:** Kindroid = single artifact minimalism, Claude-Code = ecosystem scale

**Connection:** Both demonstrate "prompts are programs" paradigm

---

### vs. Thinking Tools (AI-First Development)

**Shared:** AI as System Owner, quality infrastructure, process memory
**Different:** Thinking Tools = comprehensive framework, Claude-Code = marketplace

**Connection:** Both show "AI operates, humans direct" shift

---

### vs. MCP Agent Mail (Coordination Infrastructure)

**Shared:** Standards-based integration, declaration over enforcement
**Different:** MCP = agent-to-agent, Claude-Code = human-to-AI capabilities

**Connection:** Both demonstrate trust-based systems (not enforcement-based)

---

## Conclusion: The Paradigm Shift

Claude Code Plugins Plus demonstrates **7 interconnected paradigm shifts** from traditional software to AI-native computing:

1. **Documentation-as-Executable:** Docs ARE programs (not supplements)
2. **Linguistic APIs:** Intent-driven interfaces (not syntax-driven)
3. **Permissions-as-Documentation:** Declaration guides (not enforcement prevents)
4. **Ambient Activation:** Context-driven behavior (not explicit commands)
5. **Standards Innovation:** Conformance differentiates (not features)
6. **Automated Quality:** Infrastructure enforces (not humans gate)
7. **AI-Native Systems:** AI operates, humans direct (not assist)

**The Meta-Paradigm:**
> **"When AI becomes the primary consumer/operator, invert the hierarchy."**

These aren't incremental improvementsâ€”they're **worldview inversions**. Adopting them requires unlearning traditional software development assumptions.

**The Future:** As AI capabilities grow, **AI-native design** will become the norm. This repository provides a working demonstration of that future, today.

---

## Artifact Metadata

```json
{
  "id": "claude-code-plugins-plus-paradigm-extraction-2025-11-20",
  "type": "distillation",
  "level": 4,
  "methodology": "Paradigm Extraction",
  "target": "https://github.com/jeremylongshore/claude-code-plugins-plus",
  "paradigms_identified": 7,
  "meta_paradigm": "Human-Centric â†’ AI-Native Computing",
  "interconnections": "All 7 paradigms form coherent worldview",
  "adoption_timeline": "12 months (phased approach)",
  "cultural_implications": "high",
  "confidence": 0.90,
  "wisdom_level": 4,
  "strategic_context": "Identify fundamental worldview shifts required for AI-native developmentâ€”these are not incremental improvements but transformative changes to architecture, culture, and mental models",
  "related": [
    "claude-code-plugins-plus-architecture-2025-11-20",
    "claude-code-plugins-plus-decision-forensics-2025-11-20",
    "claude-code-plugins-plus-anti-library-2025-11-20",
    "claude-code-plugins-plus-vision-alignment-2025-11-20",
    "claude-code-plugins-plus-process-memory-2025-11-20",
    "claude-code-plugins-plus-meta-patterns-2025-11-20"
  ]
}
```
